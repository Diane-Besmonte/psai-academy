{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-IqJAMkwnCF"
      },
      "source": [
        "# Advanced Retrieval with LangChain\n",
        "\n",
        "In the following notebook, we'll explore various methods of advanced retrieval using LangChain!\n",
        "\n",
        "We'll touch on:\n",
        "\n",
        "- Naive Retrieval\n",
        "- Best-Matching 25 (BM25)\n",
        "- Multi-Query Retrieval\n",
        "- Parent-Document Retrieval\n",
        "- Contextual Compression (a.k.a. Rerank)\n",
        "- Ensemble Retrieval\n",
        "- Semantic chunking\n",
        "\n",
        "We'll also discuss how these methods impact performance on our set of documents with a simple RAG chain.\n",
        "\n",
        "There will be two breakout rooms:\n",
        "\n",
        "- ü§ù Breakout Room Part #1\n",
        "  - Task 1: Getting Dependencies!\n",
        "  - Task 2: Data Collection and Preparation\n",
        "  - Task 3: Setting Up QDrant!\n",
        "  - Task 4-10: Retrieval Strategies\n",
        "- ü§ù Breakout Room Part #2\n",
        "  - Activity: Evaluate with Ragas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rKP3hgHivpe"
      },
      "source": [
        "# ü§ù Breakout Room Part #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xes8oT-xHN7"
      },
      "source": [
        "## Task 1: Getting Dependencies!\n",
        "\n",
        "We're going to need a few specific LangChain community packages, like OpenAI (for our [LLM](https://platform.openai.com/docs/models) and [Embedding Model](https://platform.openai.com/docs/guides/embeddings)) and Cohere (for our [Reranker](https://cohere.com/rerank))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7OHJXzfyJyA"
      },
      "source": [
        "We'll also provide our OpenAI key, as well as our Cohere API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LttlDQUYgSI",
        "outputId": "9dca95ab-4d02-4adf-ec3f-cb831326dc54"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iUahNiJyQbv",
        "outputId": "78bf06ef-2ee8-46c3-f73d-27958b4dd79b"
      },
      "outputs": [],
      "source": [
        "os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw304iAFyRtl"
      },
      "source": [
        "## Task 2: Data Collection and Preparation\n",
        "\n",
        "We'll be using our Loan Data once again - this time the strutured data available through the CSV!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A92NC2QZzCsi"
      },
      "source": [
        "### Data Preparation\n",
        "\n",
        "We want to make sure all our documents have the relevant metadata for the various retrieval strategies we're going to be applying today."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GshBjVRJZ6p8"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "loader = CSVLoader(\n",
        "    file_path=f\"./data/complaints.csv\",\n",
        "    metadata_columns=[\n",
        "      \"Date received\", \n",
        "      \"Product\", \n",
        "      \"Sub-product\", \n",
        "      \"Issue\", \n",
        "      \"Sub-issue\", \n",
        "      \"Consumer complaint narrative\", \n",
        "      \"Company public response\", \n",
        "      \"Company\", \n",
        "      \"State\", \n",
        "      \"ZIP code\", \n",
        "      \"Tags\", \n",
        "      \"Consumer consent provided?\", \n",
        "      \"Submitted via\", \n",
        "      \"Date sent to company\", \n",
        "      \"Company response to consumer\", \n",
        "      \"Timely response?\", \n",
        "      \"Consumer disputed?\", \n",
        "      \"Complaint ID\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "loan_complaint_data = loader.load()\n",
        "\n",
        "for doc in loan_complaint_data:\n",
        "    doc.page_content = doc.metadata[\"Consumer complaint narrative\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gQphb6y0C0S"
      },
      "source": [
        "Let's look at an example document to see if everything worked as expected!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkUkCf7DaMiq",
        "outputId": "e90bd5da-1d87-423b-838a-cb6efc16b199"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': './data/complaints.csv', 'row': 0, 'Date received': '03/27/25', 'Product': 'Student loan', 'Sub-product': 'Federal student loan servicing', 'Issue': 'Dealing with your lender or servicer', 'Sub-issue': 'Trouble with how payments are being handled', 'Consumer complaint narrative': \"The federal student loan COVID-19 forbearance program ended in XX/XX/XXXX. However, payments were not re-amortized on my federal student loans currently serviced by Nelnet until very recently. The new payment amount that is effective starting with the XX/XX/XXXX payment will nearly double my payment from {$180.00} per month to {$360.00} per month. I'm fortunate that my current financial position allows me to be able to handle the increased payment amount, but I am sure there are likely many borrowers who are not in the same position. The re-amortization should have occurred once the forbearance ended to reduce the impact to borrowers.\", 'Company public response': 'None', 'Company': 'Nelnet, Inc.', 'State': 'IL', 'ZIP code': '60030', 'Tags': 'None', 'Consumer consent provided?': 'Consent provided', 'Submitted via': 'Web', 'Date sent to company': '03/27/25', 'Company response to consumer': 'Closed with explanation', 'Timely response?': 'Yes', 'Consumer disputed?': 'N/A', 'Complaint ID': '12686613'}, page_content=\"The federal student loan COVID-19 forbearance program ended in XX/XX/XXXX. However, payments were not re-amortized on my federal student loans currently serviced by Nelnet until very recently. The new payment amount that is effective starting with the XX/XX/XXXX payment will nearly double my payment from {$180.00} per month to {$360.00} per month. I'm fortunate that my current financial position allows me to be able to handle the increased payment amount, but I am sure there are likely many borrowers who are not in the same position. The re-amortization should have occurred once the forbearance ended to reduce the impact to borrowers.\")"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loan_complaint_data[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWaQpdHl0Gzc"
      },
      "source": [
        "## Task 3: Setting up QDrant!\n",
        "\n",
        "Now that we have our documents, let's create a QDrant VectorStore with the collection name \"LoanComplaints\".\n",
        "\n",
        "We'll leverage OpenAI's [`text-embedding-3-small`](https://openai.com/blog/new-embedding-models-and-api-updates) because it's a very powerful (and low-cost) embedding model.\n",
        "\n",
        "> NOTE: We'll be creating additional vectorstores where necessary, but this pattern is still extremely useful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NT8ihRJbYmMT"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Qdrant\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "vectorstore = Qdrant.from_documents(\n",
        "    loan_complaint_data,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"LoanComplaints\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x2SS4Rh0hiN"
      },
      "source": [
        "## Task 4: Naive RAG Chain\n",
        "\n",
        "Since we're focusing on the \"R\" in RAG today - we'll create our Retriever first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEH7X5Ai08FH"
      },
      "source": [
        "### R - Retrieval\n",
        "\n",
        "This naive retriever will simply look at each review as a document, and use cosine-similarity to fetch the 10 most relevant documents.\n",
        "\n",
        "> NOTE: We're choosing `10` as our `k` here to provide enough documents for our reranking process later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GFDPrNBtb72o"
      },
      "outputs": [],
      "source": [
        "naive_retriever = vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbBhyQjz06dx"
      },
      "source": [
        "### A - Augmented\n",
        "\n",
        "We're going to go with a standard prompt for our simple RAG chain today! Nothing fancy here, we want this to mostly be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7uSz-Dbqcoki"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_TEMPLATE = \"\"\"\\\n",
        "You are a helpful and kind assistant. Use the context provided below to answer the question.\n",
        "\n",
        "If you do not know the answer, or are unsure, say you don't know.\n",
        "\n",
        "Query:\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlRzpb231GGJ"
      },
      "source": [
        "### G - Generation\n",
        "\n",
        "We're going to leverage `gpt-4.1-nano` as our LLM today, as - again - we want this to largely be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "c-1t9H60dJLg"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat_model = ChatOpenAI(model=\"gpt-4.1-nano\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg3QRGzA1M2x"
      },
      "source": [
        "### LCEL RAG Chain\n",
        "\n",
        "We're going to use LCEL to construct our chain.\n",
        "\n",
        "> NOTE: This chain will be exactly the same across the various examples with the exception of our Retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0bvstS7mdOW3"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from operator import itemgetter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "naive_retrieval_chain = (\n",
        "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
        "    # \"question\" : populated by getting the value of the \"question\" key\n",
        "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
        "    {\"context\": itemgetter(\"question\") | naive_retriever, \"question\": itemgetter(\"question\")}\n",
        "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
        "    #              by getting the value of the \"context\" key from the previous step\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
        "    #              into the LLM and stored in a key called \"response\"\n",
        "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izKujhNb1ZG8"
      },
      "source": [
        "Let's see how this simple chain does on a few different prompts.\n",
        "\n",
        "> NOTE: You might think that we've cherry picked prompts that showcase the individual skill of each of the retrieval strategies - you'd be correct!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "LI-5ueEddku9",
        "outputId": "7f3cec18-5f4e-41bb-cf71-51ba0be5388e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided context, the most common issue with loans appears to be problems related to handling and processing by loan servicers, including errors in loan balances, misapplied payments, incorrect loan status reporting, and poor communication or transparency. Many complaints also involve issues with dealing with lenders or servicers, such as receiving bad or inconsistent information about loans, errors in credit reporting, difficulties with repayment plans, and mishandling of loan transfer or privacy violations.'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "43zdcdUydtXh",
        "outputId": "db874e67-f568-4ed1-b863-b7c17b387052"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, based on the provided complaints, there were instances where complaints did not get handled in a timely manner. Specifically, at least one complaint was marked as \"Not timely response,\" indicating it was not handled promptly. For example, the complaint received on 03/28/25 from Mohela regarding a loan application issue was marked as \"No\" under \"Timely response,\" suggesting it was delayed beyond the expected time frame. Additionally, some complaints mention delays of several weeks or over a year in getting resolution.\\n\\nTherefore, yes, some complaints in this dataset did not get handled in a timely manner.'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "lpG6rlvvvKFq",
        "outputId": "a1b330b0-628e-41be-d829-9c1d55e781f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'People often failed to pay back their loans due to a combination of factors highlighted in the complaints:\\n\\n1. **Lack of Clear Communication and Awareness:** Many borrowers were not adequately informed about when their payments would resume, the specifics of their loan balances, or any changes in their loan status. For example, some were unaware their loans had gone into delinquency or were surprised by sudden reporting to credit bureaus.\\n\\n2. **Difficulty Accessing or Understanding Payment Options:** Several complainants faced challenges in setting up manageable repayment plans or navigating online systems that failed or provided confusing information. They often reported being locked out of portals or not receiving proper guidance on deferment, forbearance, or repayment options.\\n\\n3. **Interest Accumulation During Forbearance/Deferment:** Borrowers experienced their interest continuing to accrue even when payments were paused, which increased total debt and extended repayment periods. This buildup of interest sometimes rendered it impossible to pay off the loans without increasing monthly payments beyond their means.\\n\\n4. **Financial Hardship and Unmanageable Payments:** Many borrowers faced financial difficulties, stagnant wages, or unemployment, making it impossible to afford the required payments. Despite efforts to negotiate or defer payments, the debt continued to grow due to interest and inadequate support.\\n\\n5. **Errors and Mismanagement by Loan Servicers:** Complaints mention errors such as incorrect balance reporting, unnotified loan transfers, and poor customer service, which contributed to confusion and inability to make timely payments.\\n\\n6. **Lack of Effective Repayment or Forgiveness Options:** Some borrowers felt misled about their repayment obligations and found they were ineligible for forgiveness programs, or the programs did not adequately address their circumstances, leaving them overwhelmed.\\n\\nOverall, the failure to pay back loans was often due to systemic issues like inadequate communication, complex or inaccessible systems, accruing interest during payment delays, and personal financial hardships‚Äîall compounded by mismanagement by loan servicers.\\n\\nIf you need more specific details or tailored explanations, feel free to ask!'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsbfQmbr1leg"
      },
      "source": [
        "Overall, this is not bad! Let's see if we can make it better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft1vt8HPR16w"
      },
      "source": [
        "## Task 5: Best-Matching 25 (BM25) Retriever\n",
        "\n",
        "Taking a step back in time - [BM25](https://www.nowpublishers.com/article/Details/INR-019) is based on [Bag-Of-Words](https://en.wikipedia.org/wiki/Bag-of-words_model) which is a sparse representation of text.\n",
        "\n",
        "In essence, it's a way to compare how similar two pieces of text are based on the words they both contain.\n",
        "\n",
        "This retriever is very straightforward to set-up! Let's see it happen down below!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qdF4wuj5R-cG"
      },
      "outputs": [],
      "source": [
        "from langchain_community.retrievers import BM25Retriever\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_documents(loan_complaint_data, )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIjJlBQ8drKH"
      },
      "source": [
        "We'll construct the same chain - only changing the retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "WR15EQG7SLuw"
      },
      "outputs": [],
      "source": [
        "bm25_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | bm25_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gi-yXCDdvJk"
      },
      "source": [
        "Let's look at the responses!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oY9qzmm3SOrF",
        "outputId": "4d4f450f-5978-460f-f242-b32407868353"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided context, the most common issue with loans, specifically student loans in this case, appears to be problems related to dealing with lenders or servicers. Common sub-issues include disputes over fees charged, difficulty applying payments correctly (e.g., applying extra funds to principal), receiving incorrect or bad information about loans, and issues with loan approval or reimbursement related to school validity. Overall, issues related to mismanagement, miscommunication, or disputes with loan servicers seem to be the most prevalent.'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "igfinyneSQkh",
        "outputId": "9752d4a9-dd16-45b1-f63f-a76e93a05eb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided information, all of the complaints in the context were marked as responded to with responses labeled as \"Closed with explanation\" and \"Timely response? Yes.\" Therefore, it appears that none of the complaints mentioned in the context were left unhandled or responded to outside of a timely manner.'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "w0H7pV_USSMQ",
        "outputId": "bdead654-3109-4143-9a30-e1d6ca8dc534"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'People failed to pay back their loans for various reasons, including issues with payment plans, miscommunication or lack of communication from lenders or servicers, problems with account management such as automatic payments being canceled or not resumed, and being misled or steered into unfavorable payment options like forbearances. In some cases, borrowers were unaware of transfers between loan servicers, did not receive important notifications, or faced technical issues with payments that were not resolved, leading to missed or reversed payments. These complications often resulted in negative impacts on credit scores and feelings of being deceived or disenfranchised.'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"'Closed with explanation' means that the complaint has been reviewed and a response has been provided by the company, explaining the outcome or reason for closing the case. It indicates that the issue has been addressed or resolved to some extent, and no further action is currently being taken on that complaint.\""
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"What does 'Closed with explanation' mean?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvg5xHaUdxCl"
      },
      "source": [
        "It's not clear that this is better or worse, if only we had a way to test this (SPOILERS: We do, the second half of the notebook will cover this)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"background-color: #204B8E; color: white; padding: 10px; border-radius: 5px;\">\n",
        "\n",
        "#### ‚ùì Question #1:\n",
        "\n",
        "Give an example query where BM25 is better than embeddings and justify your answer.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"background-color: #204B8E; color: white; padding: 10px; border-radius: 5px;\">\n",
        "\n",
        "#### Answer:\n",
        "\n",
        "- Example Query: What does 'Closed with explanation' mean?\n",
        "- Explanation: The example query is better than embeddings because it contains specific words or phrases that exactly appear in the dataset. BM25 works by matching the exact words in the query with the dataset or information from document/s. So it can easily find all complaints where the company response was \"Closed with explanation\" and return documents that give context about how and why that response was used.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-dcbFn2vpZF"
      },
      "source": [
        "## Task 6: Contextual Compression (Using Reranking)\n",
        "\n",
        "Contextual Compression is a fairly straightforward idea: We want to \"compress\" our retrieved context into just the most useful bits.\n",
        "\n",
        "There are a few ways we can achieve this - but we're going to look at a specific example called reranking.\n",
        "\n",
        "The basic idea here is this:\n",
        "\n",
        "- We retrieve lots of documents that are very likely related to our query vector\n",
        "- We \"compress\" those documents into a smaller set of *more* related documents using a reranking algorithm.\n",
        "\n",
        "We'll be leveraging Cohere's Rerank model for our reranker today!\n",
        "\n",
        "All we need to do is the following:\n",
        "\n",
        "- Create a basic retriever\n",
        "- Create a compressor (reranker, in this case)\n",
        "\n",
        "That's it!\n",
        "\n",
        "Let's see it in the code below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "psHvO2K1v_ZQ"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain_cohere import CohereRerank\n",
        "\n",
        "compressor = CohereRerank(model=\"rerank-v3.5\")\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=naive_retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TA9RB2x-j7P"
      },
      "source": [
        "Let's create our chain again, and see how this does!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "1BXqmxvHwX6T"
      },
      "outputs": [],
      "source": [
        "contextual_compression_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | compression_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V3iGpokswcBb",
        "outputId": "f15d2aa1-5e8b-417d-f623-eb835d072e59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided context, a common issue with loans, particularly student loans, is dealing with errors and misconduct by servicers, such as errors in loan balances, misapplied payments, wrongful denials of payment plans, and mishandling of account information. Additionally, difficulties arise from the accumulation of interest during forbearance or deferment, which can extend repayment periods and increase total debt. Overall, issues related to poor servicing, misinformation, and handling of payments seem to be prevalent problems.'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "7u_k0i4OweUd",
        "outputId": "be5fccc8-2352-4189-c524-bbeaa28cf799"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided information, yes, there are complaints that did not get handled in a timely manner. Several complaints mention delays of over a year or multiple months before receiving a response or resolution. For example, one complaint states it has been nearly 18 months with no resolution, and others mention waiting over 1 year for a response.'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "zn1EqaGqweXN",
        "outputId": "42bc5972-4164-46eb-f49d-4272f39bb89b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"People failed to pay back their loans often due to a combination of factors including a lack of clear information about repayment obligations, difficulties with managing accumulating interest, and unforeseen issues related to loan transfers and communication failures. Specifically, some borrowers were unaware they needed to repay their loans, did not receive proper notifications or documentation, or faced complications like interest that continued to grow even when they couldn't afford to make payments. Additionally, poor communication from lenders and servicers about payment plans, loan status, and changes in loan management contributed to borrowers being unable to meet their repayment responsibilities.\""
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEbT0g2S-mZ4"
      },
      "source": [
        "We'll need to rely on something like Ragas to help us get a better sense of how this is performing overall - but it \"feels\" better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqbghrBEQNn5"
      },
      "source": [
        "## Task 7: Multi-Query Retriever\n",
        "\n",
        "Typically in RAG we have a single query - the one provided by the user.\n",
        "\n",
        "What if we had....more than one query!\n",
        "\n",
        "In essence, a Multi-Query Retriever works by:\n",
        "\n",
        "1. Taking the original user query and creating `n` number of new user queries using an LLM.\n",
        "2. Retrieving documents for each query.\n",
        "3. Using all unique retrieved documents as context\n",
        "\n",
        "So, how is it to set-up? Not bad! Let's see it down below!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "pfM26ReXQjzU"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
        "    retriever=naive_retriever, llm=chat_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "1vRc129jQ5WW"
      },
      "outputs": [],
      "source": [
        "multi_query_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | multi_query_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "CGgNuOb3Q3M9",
        "outputId": "c5273ecf-da35-40b8-fbdb-0f8beab425f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The most common issue with loans, based on the complaints provided, appears to be mismanagement and poor communication by loan servicers. Specific problems include:\\n\\n- Errors in loan balances, interest calculations, or misapplied payments.\\n- Inaccurate or misleading information about loan status, balances, or repayment terms.\\n- Lack of proper notification or communication regarding account status, default, or transfer of loans.\\n- Difficulties in applying payments correctly, especially applying extra funds to principal or paying off loans early.\\n- Wrongful reporting to credit bureaus, such as incorrect default status or late payments without proper notice.\\n- Mishandling of repayment plans and failure to provide accurate information about options.\\n- Unauthorized transfer and servicing of loans without borrower consent or notification.\\n- Failure to properly address disputes or rectify errors, leading to credit damage and financial hardship.\\n\\nOverall, these issues highlight a pattern of servicer mismanagement, inadequate customer service, and lack of transparency, which are common sources of problems with student loans and other types of borrowing.'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aAlSthxrRDBC",
        "outputId": "230ff807-23ae-4d25-8d11-cfdbed0b77cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Yes, based on the provided complaints, some complaints indicate that complaints were not handled in a timely manner. Specifically:\\n\\n- The complaint with 'Timely response?' marked as 'No' from MOHELA (Complaint ID: 12739706) states that the response was not timely, noting delays beyond the expected response time.\\n- Similarly, the complaint from EdFinancial Services (Complaint ID: 12823876) also shows a 'Timely response?' marked as 'Yes' or 'No' depending on the specific case, but some explicitly mention delays of multiple weeks or over 30 days.\\n- Furthermore, several complaints note that the company failed to respond or follow up within the expected timeframe, leading to ongoing issues and frustration.\\n\\nIn summary, multiple complaints confirm that some complaints did not get handled in a timely manner.\""
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "Uv1mpCK8REs4",
        "outputId": "00fbc22a-ed9b-4613-9695-0b179e3f8369"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'People failed to pay back their loans primarily due to issues such as administrative errors, miscommunication, and misconduct by loan servicers. Many borrowers were misinformed or not adequately informed about repayment options like Income-Driven Repayment plans, income-based repayment, or rehabilitation programs, leading them to be steered into long-term forbearances or unmanageable debt situations. Additionally, systemic problems such as errors in loan balances, misapplied payments, wrongful default reporting, and failure to properly notify borrowers contributed to defaults. In some cases, borrowers experienced financial hardship, unemployment, or health issues, and were not given sufficient support or guidance to manage their repayment, resulting in missed payments and defaults.'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"background-color: #204B8E; color: white; padding: 10px; border-radius: 5px;\">\n",
        "\n",
        "#### ‚ùì Question #2:\n",
        "\n",
        "Explain how generating multiple reformulations of a user query can improve recall.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"background-color: #204B8E; color: white; padding: 10px; border-radius: 5px;\">\n",
        "\n",
        "### Answer:\n",
        "\n",
        "- Reformulating a user query means creating different versions of the same question or like having rephrased same query. This can improve recall because some documents might use other words or phrases that mean the same thing. By having multiple query versions of the user query, the system has a better change of finding more relevant documents even if they don't exactly match the original question exactly.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDEawBf_d_3G"
      },
      "source": [
        "## Task 8: Parent Document Retriever\n",
        "\n",
        "A \"small-to-big\" strategy - the Parent Document Retriever works based on a simple strategy:\n",
        "\n",
        "1. Each un-split \"document\" will be designated as a \"parent document\" (You could use larger chunks of document as well, but our data format allows us to consider the overall document as the parent chunk)\n",
        "2. Store those \"parent documents\" in a memory store (not a VectorStore)\n",
        "3. We will chunk each of those documents into smaller documents, and associate them with their respective parents, and store those in a VectorStore. We'll call those \"child chunks\".\n",
        "4. When we query our Retriever, we will do a similarity search comparing our query vector to the \"child chunks\".\n",
        "5. Instead of returning the \"child chunks\", we'll return their associated \"parent chunks\".\n",
        "\n",
        "Okay, maybe that was a few steps - but the basic idea is this:\n",
        "\n",
        "- Search for small documents\n",
        "- Return big documents\n",
        "\n",
        "The intuition is that we're likely to find the most relevant information by limiting the amount of semantic information that is encoded in each embedding vector - but we're likely to miss relevant surrounding context if we only use that information.\n",
        "\n",
        "Let's start by creating our \"parent documents\" and defining a `RecursiveCharacterTextSplitter`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "qJ53JJuMd_ZH"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from qdrant_client import QdrantClient, models\n",
        "\n",
        "parent_docs = loan_complaint_data\n",
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=750)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOpXfVUH3gL3"
      },
      "source": [
        "We'll need to set up a new QDrant vectorstore - and we'll use another useful pattern to do so!\n",
        "\n",
        "> NOTE: We are manually defining our embedding dimension, you'll need to change this if you're using a different embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzFc-_9HlGQ-",
        "outputId": "223662dd-c36f-42f7-d1b0-b086e571484e"
      },
      "outputs": [],
      "source": [
        "from langchain_qdrant import QdrantVectorStore\n",
        "\n",
        "client = QdrantClient(location=\":memory:\")\n",
        "\n",
        "client.create_collection(\n",
        "    collection_name=\"full_documents\",\n",
        "    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE)\n",
        ")\n",
        "\n",
        "parent_document_vectorstore = QdrantVectorStore(\n",
        "    collection_name=\"full_documents\", embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"), client=client\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf_g95FA3s6w"
      },
      "source": [
        "Now we can create our `InMemoryStore` that will hold our \"parent documents\" - and build our retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "BpWVjPf4fLUp"
      },
      "outputs": [],
      "source": [
        "store = InMemoryStore()\n",
        "\n",
        "parent_document_retriever = ParentDocumentRetriever(\n",
        "    vectorstore = parent_document_vectorstore,\n",
        "    docstore=store,\n",
        "    child_splitter=child_splitter,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoYmSWfE32Zo"
      },
      "source": [
        "By default, this is empty as we haven't added any documents - let's add some now!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "iQ2ZzfKigMZc"
      },
      "outputs": [],
      "source": [
        "parent_document_retriever.add_documents(parent_docs, ids=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI7Tip1335rE"
      },
      "source": [
        "We'll create the same chain we did before - but substitute our new `parent_document_retriever`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Qq_adt2KlSqp"
      },
      "outputs": [],
      "source": [
        "parent_document_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | parent_document_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNolUVQb4Apt"
      },
      "source": [
        "Let's give it a whirl!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "TXB5i89Zly5W",
        "outputId": "94c240be-7c5b-4c58-9eee-56d93285a054"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The most common issue with loans, based on the provided context, appears to be problems related to the handling and management of student loans. Specifically, frequent issues include:\\n\\n- Struggling to repay loans due to financial hardship and lack of proper information about the long-term consequences.\\n- Problems with loan consolidation, including lack of disclosure, unexpected payment amounts, and failure to provide clear terms.\\n- Discrepancies and increases in interest rates, leading to confusion and unfair charges.\\n- Incorrect reporting on credit reports, causing significant drops in credit scores.\\n- General mismanagement and lack of transparency from loan servicers.\\n\\nOverall, a prevalent theme is inadequate communication, transparency, and proper management of student loans, which contribute to repayment difficulties and financial hardship for borrowers.'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V5F1T-wNl3cg",
        "outputId": "9b81e72e-5db7-4b8a-b25b-400ea0df5335"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided complaints, yes, several complaints were not handled in a timely manner. Specifically, the complaint with ID 12709087 received on 03/28/25 was marked as \"No\" for timely response, and the complaint with ID 12935889 received on 04/11/25 also was marked as \"No.\" \\n\\nAdditionally, multiple complaints describe delays, very long wait times on calls (sometimes hours), and a failure to receive responses within the expected timeframes. Therefore, it appears that some complaints did not get handled promptly.'"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ZqARszGzvGcG",
        "outputId": "8867f83c-db13-4db4-d57f-9bd51d32cd8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'People often fail to pay back their loans due to various challenges, such as financial hardship, unemployment, or mismanagement of the loan process. In the provided context, specific reasons include:\\n\\n1. **Financial Hardship and Unemployment:** For example, a borrower enrolled in a private college that closed unexpectedly and was misled about the value of the degree, resulting in difficulties securing employment and making loan payments.\\n\\n2. **Lack of Transparency and Misrepresentation:** Borrowers were misinformed about the manageability of their loans, the long-term consequences, or the status of their school, which affected their ability to prepare financially.\\n\\n3. **Institutional Issues and College Closure:** Colleges facing financial instability or closing can lead borrowers to struggle with repayment, especially if they were misled about the institution‚Äôs stability and job prospects after graduation.\\n\\n4. **Administrative and Servicing Errors:** Problems such as loans being reported as delinquent prematurely, or payments being expected to start before the grace period without proper communication, can also prevent timely repayment.\\n\\n5. **Legal and Verification Challenges:** Invalid or unverified debt claims and issues with loan ownership can complicate repayment, leading some to stop or delay payments.\\n\\nIn summary, failure to repay loans can stem from economic hardship, inadequate information, institutional issues, and administrative errors.'"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B41cj42s4DPM"
      },
      "source": [
        "Overall, the performance *seems* largely the same. We can leverage a tool like [Ragas]() to more effectively answer the question about the performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUrIBKl_TwS9"
      },
      "source": [
        "## Task 9: Ensemble Retriever\n",
        "\n",
        "In brief, an Ensemble Retriever simply takes 2, or more, retrievers and combines their retrieved documents based on a rank-fusion algorithm.\n",
        "\n",
        "In this case - we're using the [Reciprocal Rank Fusion](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf) algorithm.\n",
        "\n",
        "Setting it up is as easy as providing a list of our desired retrievers - and the weights for each retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "8j7jpZsKTxic"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import EnsembleRetriever\n",
        "\n",
        "retriever_list = [bm25_retriever, naive_retriever, parent_document_retriever, compression_retriever, multi_query_retriever]\n",
        "equal_weighting = [1/len(retriever_list)] * len(retriever_list)\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(\n",
        "    retrievers=retriever_list, weights=equal_weighting\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpo9Psl5hhJ-"
      },
      "source": [
        "We'll pack *all* of these retrievers together in an ensemble."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "KZ__EZwpUKkd"
      },
      "outputs": [],
      "source": [
        "ensemble_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | ensemble_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSsvHpRMj24L"
      },
      "source": [
        "Let's look at our results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lMvqL88UQI-",
        "outputId": "d86dd5f7-0a13-4836-c0ce-cc4c431fd889"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The most common issues with student loans, based on the complaints data provided, appear to revolve around the following themes:\\n\\n1. **Dealing with lenders or servicers:** Many complaints involve poor communication, lack of transparency, or mishandling of loan accounts, including incorrect reporting of status, delinquencies, or balances.\\n\\n2. **Errors in loan information:** Multiple complaints highlight incorrect data on credit reports, inaccurate account statuses (e.g., showing delinquent when in fact loans are current), or discrepancies in loan balances and interest calculations.\\n\\n3. **Problems with payment handling:** Borrowers report issues applying payments correctly, only being able to pay interest rather than principal, or being unable to pay off smaller loans faster due to servicer restrictions.\\n\\n4. **Misleading or incomplete information:** Complaints often involve loan servicers providing false or misleading information about loan terms, interest accrual, or repayment options, leading borrowers to make uninformed decisions.\\n\\n5. **Lack of assistance or support:** Many borrowers feel they do not receive adequate guidance or support when facing financial hardship, and some experience unhelpful customer service, making it difficult to manage repayment or resolve errors.\\n\\n6. **Issues with loan consolidation or discharge:** Complaints include improper handling of consolidation, lack of disclosure, or difficulties in discharging or discharging loans under certain conditions.\\n\\n7. **Problems with loan transfer or reporting:** Some report being unaware of loan transfers between servicers, or having their credit reports reflect delinquencies and defaults inaccurately due to servicer errors.\\n\\n**In summary, the most common issue appears to be the mishandling and misreporting of loan information by servicers, leading to confusion, inaccurate credit reporting, and difficulties in managing repayment.**'"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "MNFWLYECURI1",
        "outputId": "b17973b5-66a9-4481-97d5-880b5754b5c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided complaints, several complaints indicate delays or failures in handling issues in a timely manner. For example:\\n\\n- The complaint with ID 12709087 from 03/28/25 reports that the complainant\\'s application was unprocessed for over 15 days, significantly beyond the 15-day response window.\\n- The complaint with ID 12975634 from 04/14/25 states that Maximus Federal Services (Aidvantage) responded to a complaint as \"Closed with explanation\" but indicates that the response was not timely, and the issue remained unresolved after months.\\n- Other complaints mention long wait times, unresolved issues spanning over months (e.g., nearly 18 months without resolution), and failure to respond or take action within expected or legal timeframes.\\n\\nTherefore, yes, **some complaints did not get handled in a timely manner**.'"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "A7qbHfWgUR4c",
        "outputId": "f7373144-59ef-4fc7-b75d-ca00e7df881e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'People failed to pay back their loans for several reasons, as reflected in the complaints:\\n\\n1. Lack of proper information and communication from loan servicers about repayment options, loan status, and upcoming payment requirements (e.g., not being notified about delinquency, not informing about available income-driven repayment plans, or mismanaging notifications about loan transfers).\\n\\n2. Difficulties with repayment plans, such as being forced into forbearance or deferment that allowed interest to accumulate, making the loan balance grow over time rather than decrease.\\n\\n3. unpleasant or unhelpful customer service, which failed to provide guidance or assistance in managing payments or adjusting repayment plans.\\n\\n4. Administrative errors and mishandling of loans, including incorrect or inconsistent reporting of account status, balances, and delinquency or default status.\\n\\n5. Inability to access or understand complex loan and account information due to lack of transparency, documentation, or guidance, leading to unintentional missed payments.\\n\\n6. Financial hardships, including unemployment, health issues, or economic downturns, which made consistent repayment difficult or impossible, often exacerbated by interest accumulation and high balances.\\n\\n7. Loan transfer issues and mismanagement, including being unaware of who owns the loan, improper reporting to credit bureaus, or errors in balancing and interest capitalization.\\n\\n8. In some cases, borrowers believed they took out manageable or private loans, but due to high interest, mismanagement, or predatory practices, their debt grew significantly, and they found repayment unmanageable.\\n\\nOverall, many people did not fail due to irresponsibility but because of systemic issues, poor communication, mismanagement, or economic hardship that made repayment difficult or impossible under the circumstances.\\n\\nIf you need more specific details, feel free to ask!'"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MopbkNJAXVaN"
      },
      "source": [
        "## Task 10: Semantic Chunking\n",
        "\n",
        "While this is not a retrieval method - it *is* an effective way of increasing retrieval performance on corpora that have clean semantic breaks in them.\n",
        "\n",
        "Essentially, Semantic Chunking is implemented by:\n",
        "\n",
        "1. Embedding all sentences in the corpus.\n",
        "2. Combining or splitting sequences of sentences based on their semantic similarity based on a number of [possible thresholding methods](https://python.langchain.com/docs/how_to/semantic-chunker/):\n",
        "  - `percentile`\n",
        "  - `standard_deviation`\n",
        "  - `interquartile`\n",
        "  - `gradient`\n",
        "3. Each sequence of related sentences is kept as a document!\n",
        "\n",
        "Let's see how to implement this!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9ciZbFEldv_"
      },
      "source": [
        "We'll use the `percentile` thresholding method for this example which will:\n",
        "\n",
        "Calculate all distances between sentences, and then break apart sequences of setences that exceed a given percentile among all distances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "66EIEWiEYl5y"
      },
      "outputs": [],
      "source": [
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "\n",
        "semantic_chunker = SemanticChunker(\n",
        "    embeddings,\n",
        "    breakpoint_threshold_type=\"percentile\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqoKmz12mhRW"
      },
      "source": [
        "Now we can split our documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "ROcV7o68ZIq7"
      },
      "outputs": [],
      "source": [
        "semantic_documents = semantic_chunker.split_documents(loan_complaint_data[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8-LNC-Xmjex"
      },
      "source": [
        "Let's create a new vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "h3sl9QjyZhIe"
      },
      "outputs": [],
      "source": [
        "semantic_vectorstore = Qdrant.from_documents(\n",
        "    semantic_documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"Loan_Complaint_Data_Semantic_Chunks\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh_r_-LHmmKn"
      },
      "source": [
        "We'll use naive retrieval for this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "odVyDUHwZftc"
      },
      "outputs": [],
      "source": [
        "semantic_retriever = semantic_vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkeiv_ojmp6G"
      },
      "source": [
        "Finally we can create our classic chain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "xWE_0J0mZveG"
      },
      "outputs": [],
      "source": [
        "semantic_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | semantic_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5pfjLQ3ms9_"
      },
      "source": [
        "And view the results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lN2j-e4Z0SD",
        "outputId": "ef483e21-7200-4dfc-b8bf-aed4f23587b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The most common issue with loans, based on the provided complaints, appears to be problems related to loan servicing and communication. Specifically, borrowers frequently report issues such as:\\n\\n- Difficulty in getting accurate or consistent information about their loan status, balances, payments, or repayment plans.\\n- Problems with auto-debit payments, including auto-payments not being processed or discrepancies in payment amounts.\\n- Lack of transparent communication about changes in loan status or servicer, leading to confusion and errors.\\n- Unauthorized reporting or mishandling of personal and financial information.\\n- Challenges in resolving disputes or correcting incorrect information on credit reports.\\n\\nOverall, issues with poor communication, administrative errors, and mishandling of borrower information seem to be most prevalent among these complaints.'"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "xdqfBH1SZ3f9",
        "outputId": "ed62b2d1-7586-46cc-aaf4-c54192a56155"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided complaints, it appears that several complaints were marked as \"Closed with explanation\" and indicate that the responses were provided in a timely manner. For example, complaints involving Nelnet, Maximus Federal Services, and EdFinancial Services all specify that the response to the consumer was \"Closed with explanation\" and that the responses were timely (\"Yes\" under \"Timely response?\"). \\n\\nHowever, the complaint narratives show ongoing issues with handling the complaints, such as lack of response to certain issues or continued violations, despite the official classification of the response being \"timely.\" \\n\\nSo, to directly answer the question: **Yes, some complaints were not handled in a timely manner,** or at least continued to have unresolved issues despite the official response being marked as timely and \"Closed with explanation.\" The ongoing nature of some problems suggests that there may have been delays or inadequate handling in some cases.'"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "rAcAObZnZ4o6",
        "outputId": "3f1cade3-41e4-4e42-ef71-048dd18e5e3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'People failed to pay back their loans for various reasons, as reflected in the complaints. Some common reasons include:\\n\\n1. Lack of accurate or transparent information from lenders or servicers, leading to confusion about their loan status or repayment obligations.\\n2. Administrative or processing issues, such as missing payments, misreported account statuses, or difficulties in documenting eligibility for loan forgiveness.\\n3. Problems with how payments are being handled, such as delays, re-amortization errors, or payment processing failures.\\n4. Disputes over the legitimacy or legality of the debt, including claims that the loan reports are invalid due to legal issues or breach of privacy laws.\\n5. Challenges arising from changes in loan status, such as loans being in default due to administrative errors or miscommunication.\\n6. Frustration with servicing practices, including delays, unresponsive communication, or alleged stall tactics by some loan servicers.\\n7. Personal financial hardship or disputes over the accuracy of account information, leading borrowers to believe they do not owe the claimed amounts or that their account status is incorrect.\\n\\nIn summary, reasons include administrative errors, lack of clear communication, legal disputes, and personal financial circumstances affecting the ability or willingness to repay loans.'"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"background-color: #204B8E; color: white; padding: 10px; border-radius: 5px;\">\n",
        "\n",
        "#### ‚ùì Question #3:\n",
        "\n",
        "If sentences are short and highly repetitive (e.g., FAQs), how might semantic chunking behave, and how would you adjust the algorithm?\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"background-color: #204B8E; color: white; padding: 10px; border-radius: 5px;\">\n",
        "\n",
        "### Answer:\n",
        "- If the sentences are short and very similar (e.g. FAQs), semantic chunking might group too many of them together, even if they are talking about different topics. This happens because the algorithm thinks they are semantically related since they use the same words over and over again. To adjust the algorithm, I would try switching from percentile to standard_deviation. That way, it won't merge unrelated sentences just because they are similar.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk2n3-pnVWDJ"
      },
      "source": [
        "# ü§ù Breakout Room Part #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SkJLYwMVZkj"
      },
      "source": [
        "<div style=\"background-color: #204B8E; color: white; padding: 10px; border-radius: 5px;\">\n",
        "\n",
        "### üèóÔ∏è Activity #1\n",
        "\n",
        "Your task is to evaluate the various Retriever methods against each other. \n",
        "You can use the loans or bills dataset.\n",
        "\n",
        "You are expected to:\n",
        "\n",
        "1. Create a \"golden dataset\"\n",
        " - Use Synthetic Data Generation (powered by Ragas, or otherwise) to create this dataset\n",
        "2. Evaluate each retriever with *retriever specific* Ragas metrics\n",
        " - Semantic Chunking is not considered a retriever method and will not be required for marks, but you may find it useful to do a \"semantic chunking on\" vs. \"semantic chunking off\" comparision between them\n",
        "3. Compile these in a list and write a small paragraph about which is best for this particular data and why.\n",
        "\n",
        "Your analysis should factor in:\n",
        "  - Cost\n",
        "  - Latency\n",
        "  - Performance\n",
        "\n",
        "> NOTE: This is **NOT** required to be completed in class. Please spend time in your breakout rooms creating a plan before moving on to writing code.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup keys and project for langchain tracing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangChain API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [],
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = f\"PSI - Retrievers Evaluation\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Data and convert to Langchain documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "df = pd.read_csv(\"data/complaints.csv\")\n",
        "df = df[df[\"Consumer complaint narrative\"].notnull()]\n",
        "\n",
        "docs = [\n",
        "    Document(page_content=row[\"Consumer complaint narrative\"], metadata={\"row\": i})\n",
        "    for i, row in df.head(20).iterrows()\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install ragas langchain-openai langchain-community datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generate Synthetic Dataset with RAGAS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4add9a27bf8f41c9ae99b45480662ec0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying SummaryExtractor:   0%|          | 0/14 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a62b543f51524f7ab8d8b9ab7a2611b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying CustomNodeFilter:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Node fb734aaf-c248-49c7-a614-8c4d0ba13f54 does not have a summary. Skipping filtering.\n",
            "Node 386395c0-348a-4fb4-a71e-8798bd57b270 does not have a summary. Skipping filtering.\n",
            "Node 89980118-bcb9-4a15-aa12-30de39145c30 does not have a summary. Skipping filtering.\n",
            "Node cd71181c-fd6a-4c3b-aba4-c0f4eb9aa9a7 does not have a summary. Skipping filtering.\n",
            "Node 2bd282f9-f775-4ba3-a88c-8088bd20cb1a does not have a summary. Skipping filtering.\n",
            "Node e385c7f9-7b17-459a-af12-24d6f9d12e87 does not have a summary. Skipping filtering.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "295734a5e0f94d19a1bd13b80c7c08cd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/54 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c2effde54d1425b80515f5156848e53",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "68d656de1caa4c8d8685789b01780b95",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e51bac6db8a463d992fb15a28e678dd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1ab0b79662848e8a71d0183b2176f6c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Samples:   0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>reference_contexts</th>\n",
              "      <th>reference</th>\n",
              "      <th>synthesizer_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Why Nelnet not re-amortize my loans after forb...</td>\n",
              "      <td>[The federal student loan COVID-19 forbearance...</td>\n",
              "      <td>The federal student loan COVID-19 forbearance ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Help me understand how Aidvantage can give me ...</td>\n",
              "      <td>[I submitted my annual Income-Driven Repayment...</td>\n",
              "      <td>According to the context, Aidvantage assigned ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How did the account transfer to Nelnet involve...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nThis account was transferred to Ne...</td>\n",
              "      <td>The account was transferred to Nelnet from XXX...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Did the account transfer to Nelnet happen afte...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nThis account was transferred to Ne...</td>\n",
              "      <td>The account was transferred to Nelnet from XXX...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How does the legal dispute involving NelNet an...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nXX/XX/XXXX I increased the amount ...</td>\n",
              "      <td>The context details a formal legal dispute whe...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          user_input  \\\n",
              "0  Why Nelnet not re-amortize my loans after forb...   \n",
              "1  Help me understand how Aidvantage can give me ...   \n",
              "2  How did the account transfer to Nelnet involve...   \n",
              "3  Did the account transfer to Nelnet happen afte...   \n",
              "4  How does the legal dispute involving NelNet an...   \n",
              "\n",
              "                                  reference_contexts  \\\n",
              "0  [The federal student loan COVID-19 forbearance...   \n",
              "1  [I submitted my annual Income-Driven Repayment...   \n",
              "2  [<1-hop>\\n\\nThis account was transferred to Ne...   \n",
              "3  [<1-hop>\\n\\nThis account was transferred to Ne...   \n",
              "4  [<1-hop>\\n\\nXX/XX/XXXX I increased the amount ...   \n",
              "\n",
              "                                           reference  \\\n",
              "0  The federal student loan COVID-19 forbearance ...   \n",
              "1  According to the context, Aidvantage assigned ...   \n",
              "2  The account was transferred to Nelnet from XXX...   \n",
              "3  The account was transferred to Nelnet from XXX...   \n",
              "4  The context details a formal legal dispute whe...   \n",
              "\n",
              "                       synthesizer_name  \n",
              "0  single_hop_specifc_query_synthesizer  \n",
              "1  single_hop_specifc_query_synthesizer  \n",
              "2  multi_hop_abstract_query_synthesizer  \n",
              "3  multi_hop_abstract_query_synthesizer  \n",
              "4  multi_hop_specific_query_synthesizer  "
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ragas.testset import TestsetGenerator\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "\n",
        "llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-nano\"))\n",
        "embedding_model = LangchainEmbeddingsWrapper(OpenAIEmbeddings())\n",
        "\n",
        "generator = TestsetGenerator(llm=llm, embedding_model=embedding_model)\n",
        "testset = generator.generate_with_langchain_docs(docs, testset_size=5)\n",
        "\n",
        "testset_df = testset.to_pandas()\n",
        "testset_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Upload Dataset to Langsmith"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Created dataset and uploaded 6 examples: Loan Complaints Retriever Dataset\n",
            "\n",
            "üöÄ Running LangSmith evaluation for: Naive\n",
            "View the evaluation results for experiment: 'Retriever Eval - Naive-221940af' at:\n",
            "https://smith.langchain.com/o/1416e1a2-8bd8-4452-a1d2-3cea46dfc419/datasets/f9ee957c-aed1-4107-b5f6-77676c208cc9/compare?selectedSessions=bfe3d4b3-e979-4fb4-ba9e-7432e176ed75\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "020817e2f1b64676abfeb87faf9f85b8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üöÄ Running LangSmith evaluation for: BM25\n",
            "View the evaluation results for experiment: 'Retriever Eval - BM25-fe256414' at:\n",
            "https://smith.langchain.com/o/1416e1a2-8bd8-4452-a1d2-3cea46dfc419/datasets/f9ee957c-aed1-4107-b5f6-77676c208cc9/compare?selectedSessions=93a408fa-10b7-48ed-9fb4-84234d5ab042\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dce1157bbcd74d7ba63850efd80d671c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üöÄ Running LangSmith evaluation for: Multi-Query\n",
            "View the evaluation results for experiment: 'Retriever Eval - Multi-Query-a0ff6f38' at:\n",
            "https://smith.langchain.com/o/1416e1a2-8bd8-4452-a1d2-3cea46dfc419/datasets/f9ee957c-aed1-4107-b5f6-77676c208cc9/compare?selectedSessions=15535e35-6dae-44e2-9504-1ffe929e5e6e\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee84b9a55ba34483999312ba246b62ab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üöÄ Running LangSmith evaluation for: Parent\n",
            "View the evaluation results for experiment: 'Retriever Eval - Parent-4f47eff1' at:\n",
            "https://smith.langchain.com/o/1416e1a2-8bd8-4452-a1d2-3cea46dfc419/datasets/f9ee957c-aed1-4107-b5f6-77676c208cc9/compare?selectedSessions=702b7639-05ae-47ed-b21c-324d1f32fec6\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "177d3b341b1b4feb84370e6b013d1978",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "from langsmith import Client\n",
        "from langsmith.evaluation import evaluate as ls_evaluate, LangChainStringEvaluator\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema import StrOutputParser\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from operator import itemgetter\n",
        "\n",
        "client = Client()\n",
        "dataset_name = \"Loan Complaints Retriever Dataset\"\n",
        "\n",
        "try:\n",
        "    ds = client.read_dataset(dataset_name=dataset_name)\n",
        "    print(f\"‚ÑπÔ∏è Reusing existing dataset: {dataset_name}\")\n",
        "except Exception:\n",
        "    ds = client.create_dataset(\n",
        "        dataset_name=dataset_name,\n",
        "        description=\"Synthetic Q&A pairs generated from loan complaints for retriever evaluation.\"\n",
        "    )\n",
        "\n",
        "    for row in testset_df.itertuples():\n",
        "        client.create_example(\n",
        "            inputs={\"question\": row.user_input},\n",
        "            outputs={\"answer\": row.reference},\n",
        "            dataset_id=ds.id\n",
        "        )\n",
        "    print(f\"‚úÖ Created dataset and uploaded {len(testset_df)} examples: {dataset_name}\")\n",
        "\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "You are a helpful assistant. Use ONLY the provided context to answer the question.\n",
        "If the answer is not in the context, say \"I don't know\".\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\")\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "cap_docs = RunnableLambda(lambda docs: docs[:4])\n",
        "\n",
        "def make_chain(retriever):\n",
        "    return (\n",
        "        {\"context\": itemgetter(\"question\") | retriever | cap_docs, \"question\": itemgetter(\"question\")}\n",
        "        | rag_prompt\n",
        "        | llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "\n",
        "# Define Retrievers\n",
        "retrievers = {\n",
        "    \"Naive\": naive_retriever,\n",
        "    \"BM25\": bm25_retriever,\n",
        "    \"Multi-Query\": multi_query_retriever,\n",
        "    # \"Rerank\": compression_retriever, # Commented out because of rate limits\n",
        "    \"Parent\": parent_document_retriever,\n",
        "    # \"Ensemble\": ensemble_retriever, # Commented out because of rate limits\n",
        "}\n",
        "\n",
        "\n",
        "qa_eval = LangChainStringEvaluator(\"qa\", config={\"llm\": ChatOpenAI(model=\"gpt-4o-mini\")})\n",
        "\n",
        "for name, retr in retrievers.items():\n",
        "    print(f\"\\nüöÄ Running LangSmith evaluation for: {name}\")\n",
        "    rag_chain = make_chain(retr)\n",
        "\n",
        "    result = ls_evaluate(\n",
        "        rag_chain.invoke, \n",
        "        data=dataset_name,\n",
        "        evaluators=[qa_eval],\n",
        "        metadata={\"retriever\": name, \"revision_id\": f\"retriever_eval_{name}\"},\n",
        "        experiment_prefix=f\"Retriever Eval - {name}\",\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWAr16a5XMub"
      },
      "source": [
        "##### HINTS:\n",
        "\n",
        "- LangSmith provides detailed information about latency and cost."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LangSmith Trace Screenshots\n",
        "\n",
        "Below are the trace images captured from LangSmith for this project.\n",
        "\n",
        "### Naive Retriever\n",
        "![Naive Retriever](images/naive.png)\n",
        "\n",
        "### BM25 Retriever\n",
        "![BM25 Retriever](images/bm25.png)\n",
        "\n",
        "### Multi-query Retriever\n",
        "![Multi-query Retriever](images/multi-query.png)\n",
        "\n",
        "### Parent Retriever\n",
        "![Parent Retriever](images/parent.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgDICngKXLGK"
      },
      "source": [
        "<div style=\"background-color: #204B8E; color: white; padding: 10px; border-radius: 5px;\">\n",
        "\n",
        "### Analysis & Observations:\n",
        "- Naive Retriever achieved the highest correctness (100%), showing it consistently returned accurate answers for all queries. It had moderate latency (4.145s) and relatively low token usage, making it both accurate and cost-efficient.\n",
        "\n",
        "- BM25 Retriever was the fastest (2.921s) and cheapest in terms of latency and cost but had lower correctness (66.67%). Its keyword-matching nature makes it fast but less reliable for nuanced queries.\n",
        "\n",
        "- Multi-Query Retriever scored high on correctness (83.33%) by leveraging query reformulations to improve recall. However, it had the highest latency (6.092s) since it executes multiple retrievals per question. Cost and tokens were moderate.\n",
        "\n",
        "- Parent Retriever matched BM25‚Äôs correctness (66.67%) and had mid-range latency (3.466s). It excels at retrieving broader context but may bring in less focused information for precise Q&A.\n",
        "\n",
        "### Conclusion:\n",
        "For this dataset, Naive Retriever is the best overall choice, combining perfect correctness with reasonable latency and cost.\n",
        "\n",
        "- BM25 Retriever is ideal if speed is the top priority and some drop in accuracy is acceptable.\n",
        "\n",
        "- Multi-Query Retriever is a strong option for complex queries where reformulating the question can uncover more relevant context, though at the expense of speed.\n",
        "\n",
        "PS: I only ran the evaluation for four retrievers to gather the metrics, as the other two retrievers were commented out due to encountering rate limit issues.\n",
        "</div>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
